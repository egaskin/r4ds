---
title: "Chapter 3, Notes + Code"
format: html
editor: visual
---

# Why this formatting?

I originally had all of chapter 1, 2, and 3 in R scripts, but then realized a "Jupyter Notebook" like experience would make things 1000x better. I've just copied and pasted the code into the cell below

# Code for 3.1 - 3.3

```{r}
#######################################
# YOU CAN FIND EXERCISES FOR CHAP 3 AT THE BOTTOM
#######################################

library(nycflights13)
library(tidyverse)
#> ── Attaching core tidyverse packages ───────────────────── tidyverse 2.0.0 ──
#> ✔ dplyr     1.1.4     ✔ readr     2.1.5
#> ✔ forcats   1.0.0     ✔ stringr   1.5.1
#> ✔ ggplot2   3.5.2     ✔ tibble    3.2.1
#> ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
#> ✔ purrr     1.0.4     
#> ── Conflicts ─────────────────────────────────────── tidyverse_conflicts() ──
#> ✖ dplyr::filter() masks stats::filter()
#> ✖ dplyr::lag()    masks stats::lag()
#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all
#>  conflicts to become errors

# to use R's base versions of filter() and lag(), have to do this:
# package_name::function_name(), examples:
  # stats::filter()
  # stats::lag()

# 3.1.2 nycflights13
# another example of package_name::function_name()
nycflights13::flights
?flights

typeof(flights) # R sees as list

# tibbles designed for larger datasets, so default printing is not cumbersome
flights # A tibble: 336,776 × 19

# ways to view tibbles
# (1)
View(flights) # best way to view all data, if in Rstudio, comes with filter!

# (2)
# print() only prints first 10 rows and however many columns fits in the console
# but can use width = Inf to change that
print(flights,width = Inf) # prints all the columns

# (3)
glimpse(flights)

# 3.1.3 dplyr basics
# 6 things dplyr verbs (functions) share:
# (1) first argument is dataframe
# (2) subsequent arguments describe which cols
# to operate on using var names (NOT quoted, "quasiquoted")
# (3) output always new dataframe
# (4) really good at one operation, so need to "|>" pipe multiple together
# (5) operate on one of the following: rows, cols, groups, or tables
# pipe takes thing on its left and passes it along to fn on its right:
# x |> f(y) = f(x,y)
# x |> f(y) |> g(z) = g(f(x,y),z)
# (6) NEVER modify their inputs, always produces new dataframe

flights |>
  filter(dest == "IAH") |> 
  group_by(year, month, day) |> 
  summarize(
    arr_delay = mean(arr_delay, na.rm = TRUE)
  )

# 3.2 Row verbs: 
# 1. filter(), 
# 2. arrange() (with desc())
# 3. distinct()
# 4. count()

# filter() keeps rows based on values of columns, slice_*() for rows by position
# filter() args:
# (1st) dataframe
# (2nd or more) conditions to keep the row
  # conditions are >, >=, <, <=, ==, !=, and
  # can be combined with & and | 

# get all the flights departing over 120 min late
flights |> filter(dep_delay > 120)

# flights departing Jan 1
flights |> 
  filter(month == 1 & day == 1)

# flights departing Jan or Feb
flights |> 
  filter(month == 1 | month == 2)
  # WHICH IS EQUIVALENT TO SHORTCUT VERSION
flights |>
  filter(month %in% c(1,2))

# to save the result of a filter operation
jan1 <- flights |> 
  filter(month == 1 & day == 1)

# common errors with filter:

# error 1: accidental = instead of ==
# flights |> 
#   filter(month = 1)
# #> Error in `filter()`:
# #> ! We detected a named input.
# #> ℹ This usually means that you've used `=` instead of `==`.
# #> ℹ Did you mean `month == 1`?

# error 2: or like english instead of explicit boolean:
flights |> 
  filter(month == 1 | 2) # doesnt throw error but is nonsensical since 2 is
# treated as a TRUE, 
# https://stackoverflow.com/questions/5681166/what-evaluates-to-true-false-in-r

# arrange() changes order of rows based on values of columns
# arrange() args:
# 1st. dataframe
# 2nd. set of column names or more complicated expressions to order by,
# if more than 1 column name given then each additional column used to break
# ties from preceding column

# this orders by departure time which is broken into 4 columns
flights |> 
  arrange(year, month, day, dep_time)

# desc() expression re-orders based on col_name in Descending order
flights |> 
  arrange(desc(dep_delay)) 

# distinct() finds all unique rows in dataset, so primarily operates on rows but
# occasionally will supply column names
# NOTE: only keeps first unique occurrence (discarding the rest!)

# remove duplicate rows if there are any
flights |> 
  distinct()

# find all unique origin and destination pairs
# and only return just the pairs (not entire rows)
flights |> 
  distinct(origin, dest)

# same as above except return entire rows whose origin/dest pairs are unique
flights |>
  distinct(origin, dest, .keep_all = TRUE)
# ^ NOTICE: how they're all jan 1 for the displayed rows. that's b/c only 1st
# occurrence of unique row is kept

# count() will count all the unique pairs, you can sort said pairs 
flights |>
  count(origin,dest,sort = TRUE)

# can add a new column with dplyr verbs
flights |>
  count(origin,dest,sort = TRUE,NEW_COLUMN = TRUE)

# 3.3 Column verbs: 
# 1. mutate(), creates new cols derived from existing cols
# 2. select(), changes which cols are present
# 3. rename(), changes names of cols
# 4. relocate(), changes positions of cols (default front)

# 3.3.1 mutate()
flights |>
  mutate(
    gain = dep_delay - arr_delay,
    speed = distance / air_time * 60,
    .before = 1 # adds columns in order given before this col index
    # alternatively 
    # .before = month # use col name instead of index
    
    )

flights |>
  mutate(
    gain = dep_delay - arr_delay,
    speed = distance / air_time * 60,
    # .after = 1, # adds columns in order given after this col index
    # alternatively
    .after = day, # use col name instead of index
    .keep = "used" # controls which cols are kept. "used" = keep only used cols
  )

# 3.3.2 select()

# select cols by name
flights |>
  select(year,month,day)

# select cols between two cols (inclusive)
flights |>
  select(year:day)

flights |>
  select(1:3)

# select cols except those from year to day (inclusive)
flights |>
  select(!year:day)

# select cols that are "is.something"
flights |>
  select(where(is.character))

# other tools WITH select (and other selecting funcs)
# starts_with("abc"), col names beginning with "abc"
# ends_with()
# contains()
# num_range("x",1:3): matches x1, x2, x3
# matches() with some regex

# rename variables as you select, using "="
flights |>
  select(tail_num = tailnum)

# for automated column naming cleanup!
janitor::clean_names(flights) # fails to find "tailnum" a problem, as v2.2.1
?janitor::clean_names()

# 3.3.3 rename() - keep all the columns but rename a few
flights |>
  rename(tail_num = tailnum)

# 3.3.4 relocate()
flights |> 
  relocate(time_hour, air_time) 

# using .before and .after arguments like mutate()
flights |> # ":" to select range
  relocate(year:dep_time, .after = time_hour)

flights |> relocate(dep_time:year) # ":" to reverse range

flights |> 
  relocate(starts_with("arr"), .before = dep_time)

library(tidyverse)
library(palmerpenguins)
library(ggthemes)


#######################################
# 3.2.5 Exercises
library(nycflights13)

# 1. In a single pipeline for each condition, find all flights that meet the 
# condition:
# Had an arrival delay of two or more hours
# Flew to Houston (IAH or HOU)
# Were operated by United, American, or Delta
# Departed in summer (July, August, and September)
# Arrived more than two hours late but didn’t leave late
# Were delayed by at least an hour, but made up over 30 minutes in flight

# we could split this into multiple filters, but i dont feel like it
# the last condition conflicts with the 2nd to last condition though, so
# i did that one by itself
flights |>
  filter(arr_delay >= 2*60 &
           dest %in% c("IAH","HOU") &
           carrier %in% c("UA","AA","DL") &
           month %in% c(7,8,9) &
           dep_delay <= 0 &
           arr_delay >= 2*60
  )

# Were delayed by at least an hour, but made up over 30 minutes in flight
# delayed part is easy, make sure dep_delay column >= 1 hr.
# made up over 30 min in flight can be done in a couple ways:
# (1) arr_time - sched_arr_time <= 30 WITH dep_delay >= 60 min
# (2) arr_delay <= 30 WITH dep_delay >= 60 min
last_condition <- flights |>
  filter(dep_delay >= 1*60 & arr_delay <= 30)
last_condition
View(last_condition)
max(last_condition["arr_delay"]) >= 30 # TRUE

# 2. Sort flights to find the flights with the longest departure delays. Find 
# the flights that left earliest in the morning.
# Answer: see longest_dep_delay and earliest below for 10 longest/shortest

# desc() for descending!
longest_dep_delay <- 
  flights |> 
  arrange(desc(dep_delay)) 

longest_dep_delay[1:10,c("flight","dep_delay")]

earliest_dep_time <-
  flights |>
  arrange(dep_time)

earliest_dep_time[1:10,c("flight","dep_time")]

# 3. Sort flights to find the fastest flights. (Hint: Try including a math 
# calculation inside of your function.)
# my original answer was a little more tedious using $ notation, this answer is 
# inspired by (and the same as) Resource 1.
# Answer:
fastest_flights <-
  flights |>
  mutate(speed = distance/air_time) |>
  arrange(desc(speed)) |>
  relocate(speed)

fastest_flights

# 4. Was there a flight on every day of 2013?
# Answer: Yes! See below.

# the number of rows equals how many unique days of 2013 had a flight
unique_month_day_pairs <- 
  flights |>
  distinct(month,day) |>
  nrow()

dim(unique_month_day_pairs)[1] == 365

# alternatively:
flights |>
  distinct(month,day) |>
  nrow() ==
  365

# 5. Which flights traveled the farthest distance? Which traveled the least 
# distance?
# Answer: see below, 1 flight went 17 mi for the shortest distance, and
# 342 flights went 4983 mi for the longest distance

# old way
# distance_sorted_flights <-
#   flights |>
#     arrange(distance) |>
#     relocate(distance)

# new way, to get number of flights meeting the distance
distance_sorted_flights <-
  flights |>
  count(distance) |>
  arrange(distance)

# least distance, top 10
distance_sorted_flights[1,1:2]

# furthest distance, top 10
# negative indexing to exclude everything except last
end_exclude_idx <- dim(distance_sorted_flights)[1]-1
distance_sorted_flights[-1:-end_exclude_idx,1:2]

# 6. Does it matter what order you used filter() and arrange() if you’re using 
# both? Why/why not? Think about the results and how much work the functions 
# would have to do.
# Answer: Yes, the order matters for the amount of work that will be done. 
# Both arrange() and filter() will have to see 
# every row of input dataframe. if we arrange() then filter() this will require 
# seeing every element of original dataframe twice. if we filter() then 
# arrange(), we will only have to arrange the elements that were filtered out, 
# which will typically be less than the number of elements in the dataframe 
# which typically will mean seeing each element less than two times. Order of 
# arrange() and filter() will NOT affect the results though (assuming filter()
# does not change the order of the output of arrange())

#######################################
# 3.2.5 Exercises
# 1. Compare dep_time, sched_dep_time, and dep_delay. How would you expect those 
# three numbers to be related?
# Answer: "sched_dep_time + dep_delay = dep_time" is my original answer, but
# this reveals that 594=600-6 instead of 554. This is because 5:54am is 6 
# minutes before 6:00am. We need to deal with the time format.
# NOTE: that b/c of different time zones we cannot easily compare times of 
# arrivals and departures.


# VERSION 2:

add_interval_to_times_col <-function(times_col,interval_col){
  
  make_military_time_leading_0 <-function(flights_time_col){
    needs_leading_0 <- flights_time_col < 1000
    col_with_leading_0 <- as.character(flights_time_col)
    col_with_leading_0[needs_leading_0] <- 
      paste0("0",col_with_leading_0[needs_leading_0])
    
    # note that the column is now STRINGS
    col_with_leading_0
  }
  
  make_minutes_leading_0 <-function(some_int_col){
    # use which() to ignore NAs
    needs_leading_0 <- which(some_int_col < 10)
    col_with_leading_0 <- as.character(some_int_col)
    col_with_leading_0[needs_leading_0] <- 
      paste0("0",col_with_leading_0[needs_leading_0])
    
    # note that the column is now STRINGS
    col_with_leading_0
  }
  
  get_hr_from_min <- function(n){
    return(abs(n) %/% 60)
  }
  
  get_min_from_min_after_hr_removed <- function(n){
    abs(n) %% 60
  }
  
  check_positive <- function(n){
    # get TRUE if positive, FALSE if negative
    # then convert to integers by doing arithmetic
    # 1 if positive, 2 if negative. for the lookup table of
    # convert_to_plus1_minus1.
    (n > 0) + 1 
  }
  
  convert_to_plus1_minus1 <- function(n){
    lookup = c(-1,1)
    lookup[n]
  }
  
  # add a leading zero (string column now)
  times_with_leading_0 <- make_military_time_leading_0(times_col)
  
  # these are integers
  interval_min <- get_min_from_min_after_hr_removed(interval_col)
  interval_hr <- get_hr_from_min(interval_col)
  interval_sign <- convert_to_plus1_minus1(check_positive(interval_col))
  times_hr <- as.integer(substr(times_with_leading_0,1,2))
  times_min <- as.integer(substr(times_with_leading_0,3,4))
  
  # print("times_with_leading_0[1:17]")
  # print(times_with_leading_0[1:17])
  # print("interval_col[1:17]")
  # print(interval_col[1:17])
  # print("times_min[1:17]")
  # print(times_min[1:17])
  # print("times_hr[1:17]")
  # print(times_hr[1:17])
  
  
  # increment the military time minutes and get the potential extra hours
  times_min <- times_min + interval_min*interval_sign
  extra_hr <- times_min %/% 60 # integer division
  times_min <- times_min %% 60 # modulus/remainder operation
  
  # increment the military time hours
  times_hr <- (times_hr + interval_hr*interval_sign + extra_hr) %% 24
  
  # convert both to strings, combine them, then convert back to int
  times_with_leading_0 <- paste0(as.character(times_hr),
                                 make_minutes_leading_0(times_min))
  
  # convert to integer to be in the HHMM or HMM format
  times_with_leading_0 <- as.integer(times_with_leading_0)
  
  # final cleanup step. when n %% 24 = 0, this should actually be 2400 (i.e.
  # should be 12am not 0am)
  find_0 <- times_with_leading_0 == 0
  
  # print("find_0")
  # print(find_0)
  # print("times_with_leading_0")
  # print(times_with_leading_0)
  
  times_with_leading_0[find_0] <- 2400
  
  times_with_leading_0
}

#### start: test cases for add_interval_to_times_col()
# note: test cases 12 and 14 show that if the final times_min minutes is a single
# digit integer (<10), appending this to the hour portion will result in 
# incorrectly formatted time. For example, if times_min = 6, and times_hr = 4
# then the final answer would be 46 instead of 406.
test_q1 = select(flights,dep_time:dep_delay)[1:10,]
new_rows <- tibble(dep_time = c(1417,600,559,406,2400,2400,2400),
                   sched_dep_time = c(1835,600,559,406,2359,2250,1700),
                   dep_delay = c(19*60 + 42,0,0,0,1,70,420))

test_q1 <- bind_rows(test_q1,new_rows)
test_q1

add_interval_to_times_col(test_q1$sched_dep_time,
                          test_q1$dep_delay)

flights_na_counts <- colSums(is.na(flights))
# flights_na_counts
flights_na_counts[flights_na_counts > 0]

#### end: test cases for add_interval_to_times_col() 

flights_q1 <- # flights question 1
  flights |>
  select(dep_time:dep_delay) |>
  # if had a filter() step, use .data$ NOT flights$
  mutate(sum_sched_dep_time_plus_dep_delay = 
           add_interval_to_times_col(.data$sched_dep_time, 
                                     .data$dep_delay),
         .before = 1
  )

flights_q1_na_counts <- colSums(is.na(flights_q1))
flights_q1_na_counts[flights_q1_na_counts > 0]

flights_q1_clean <- flights_q1 %>%
  filter(
    !is.na(dep_time),
    !is.na(dep_delay),
    !is.na(sched_dep_time)
  )

flights_clean <- flights |>
  filter(
    !is.na(dep_time),
    !is.na(dep_delay),
    !is.na(sched_dep_time)
  )

flights_clean_na_counts <- colSums(is.na(flights_clean))
flights_clean_na_counts[flights_clean_na_counts > 0]

flights_q1_clean_na_counts <- colSums(is.na(flights_q1_clean))
flights_q1_clean_na_counts[flights_q1_clean_na_counts > 0]

# flights_q1_clean[flights_q1_clean$sum_sched_dep_time_plus_dep_delay != flights_clean$dep_time,]
# reveals the bad rows!   
print( n = 29,
       flights_q1_clean[flights_q1_clean$sum_sched_dep_time_plus_dep_delay != flights_clean$dep_time,]
)

# VERSION 1:
# DOESNT WORK BECAUSE e.g. 530 = 5:30 am. can't simply add: 530+65=595.
# df <-
# flights |>
#   select(dep_time:dep_delay) |>
#   mutate(sum_dep_sched_plus_delay = sched_dep_time + minutes(dep_delay),
#          .before = 1)
# df

# 2. Brainstorm as many ways as possible to select dep_time, dep_delay, arr_time, 
# and arr_delay from flights.
# Answer: Assuming a single select statement used without other column verbs 
# (otherwise very many possibilities). select(flights, ...)
select(flights,dep_time, dep_delay, arr_time, arr_delay)
select(flights,c(4,6,7,9))
select(flights,-1:-3,-5,-8,-10:-ncol(flights)) # EQUIVALENT -c(1:3,5,8,10:ncol(flights))
select(flights,all_of(c("dep_time", "dep_delay", "arr_time", "arr_delay")))
select(flights,any_of(c("dep_time", "dep_delay", "arr_time", "arr_delay")))
select(flights,! any_of(c("year", "month", "day", "sched_dep_time", 
                          "sched_arr_time", "carrier", "flight", "tailnum", 
                          'origin', "dest", "air_time", "distance", "hour", 
                          "minute", "time_hour")))

# 3. What happens if you specify the name of the same variable multiple times in a 
# select() call?
# Answer: It seems only the first time its specified matters, the rest are 
# ignored. Note: we also learned that select can reorder the columns into the
# order we select them in.

flights |> select(dep_time,dep_time,year,year,year,dep_time)

# 4. What does the any_of() function do? Why might it be helpful in conjunction 
# with this vector?
# Answer: select(df, any_of()) selects from df any column whose name matches a 
# string from the vector, and ignores names not present
variables <- c("year", "month", "day", "dep_delay", "arr_delay", "DUMMY")
flights |> select(any_of(variables))

# 5. Does the result of running the following code surprise you? How do the 
# select helpers deal with upper and lower case by default? How can you change 
# that default?
# Answer: Yes, I am surprised. The select helpers seem to ignore case.
flights |> select(contains("TiMe"))

# 6. Rename air_time to air_time_min to indicate units of measurement and move 
# it to the beginning of the data frame.
# Answer: see below.
flights |> 
  rename(air_time_min = air_time) |>
  relocate(air_time_min)

# 7. Why doesn’t the following work, and what does the error mean?
# Answer: select ONLY returns selected columns in new dataframe, so add 
# arr_delay to select statement
flights |>
  select(tailnum, arr_delay) |> 
  arrange(arr_delay)


```

# 3.4 The pipe

-   pipe operator: use the base R version unless you HAVE to use magrittr's
    -   "\|\>" for base R
        -   slightly more efficient
        -   good for simple pipelines
        -   only need to pipe into first argument of funcs
        -   fewer dependencies
    -   "%\>%" from magrittr in tidyverse
        -   allows dot "." to control where arguments go
        -   allows piping into 2nd/third arguments
        -   more complex pipes
-   pipe typing SHORTCUT: `Ctrl + Shift + M`
-   pipe is good for combining multiple verbs, to answer multifaceted questions like "find fastest flights to Houston's IAH airport"

```{r}
flights |>
  filter(dest == "IAH") |>
  mutate(mph = distance / air_time * 60) |>
  select(year:day, dep_time, carrier, flight, mph) |>
  arrange(desc(mph))
```

# 3.5 Groups

-   dplyr allows you to divide dataset into groups
-   group functions: group_by(), summarize(), and "slice\_" family

## 3.5.1 `group_by()`

-   group_by() doesn't change the data, but it groups the data by some attribute/feature then

    -   subsequent operations/verbs will work by that grouping!
    -   grouped features is a class of the data frame

    ```{r}
    attr(flights,"class") # without grouping

    # example grouping by month
    flights |>
      group_by(month) |>
      attr("class") # "grouped_df" added to class after grouping
      # don't use the full attributes call because row names prints out LONG
      # attributes() # groups added to $class attribute!
    ```

    ## 3.5.2 `summarize()`

-   summarize() =

    -   most important group operation
    -   if being used for single summary statistic reduces data frame to have single row for each group

```{r}
flights |>
  group_by(month) |> 
  summarize(
    
    # calculate the average delay by month
    # mean(dep_delay) will result in NA coercion, we 
    # need to add na.rm = TRUE
    avg_delay = mean(dep_delay, na.rm = TRUE),
    
    
    # count the number of rows (flights) in each column
    n = n()
  )
  
```

## 3.5.3 `slice_` functions

-   five functions that are handy for extracting specific rows in each group:

    1.  `df |> slice_head(n=1)` = take first n rows from each group
    2.  `df |> slice_tail(n=1)` = take last n rows from each group
    3.  `df |> slice__head_min(x, n=1)` = takes n rows from each group with smallest value of column `x` (returning all ties)
    4.  `df |> slice__head_max(x, n=1)` = takes n rows from each group with largest value of column `x`(returning all ties)
    5.  `df |> slice_sample(n=1)` takes n random rows from each group

    -   instead of `n =` you can use `prop = 0.1` to select 10% of rows in each group
    -   similar to `summarize()` but get whole corresponding row (rows if tie) instead of single summary statistic

*Example below*: find flights most delayed upon arrival, grouped by destination

```{r}
# notice, this returns 108 rows but there are
# only 105 destinations. this is because all tires for max are returned
flights |> 
  group_by(dest) |> 
  slice_max(arr_delay, n = 1) |>
  relocate(dest)

# if we want exactly 1 row per group, we can
# set with_ties = FALSE
flights |> 
  group_by(dest) |> 
  slice_max(arr_delay, n = 1, with_ties = FALSE) |>
  relocate(dest)
```

## 3.5.4 Group by multiple variables

-   **summarizing by group issue**: summarizing peels off the last group unless you use the `.groups` argument
-   `.groups =`
    -   `"drop"` drops all grouping
    -   `"keep"` preserves all grouping
    -   `"drop_last"` will suppress the warning message that

```{r}
daily <- flights |>
  group_by(year, month, day)

# below will generate warning message: `summarise()` has grouped output by 'year', 'month'. You can override using the `.groups` argument.
daily |> summarize(n=n(),mean_dep_time = mean(dep_time, na.rm = TRUE))

daily |> summarize(n=n(),mean_dep_time = mean(dep_time, na.rm = TRUE), .groups = "keep")
```

## 3.5.5 Ungrouping

-   summarizing an ungrouped dataframe simply results in treating the whole dataframe as 1 group

```{r}
# to ungroup a dataframe
daily |> 
  ungroup()

# summarizing an ungrouped dataframe
daily |>
  ungroup() |>
  summarize(
    avg_delay = mean(dep_delay, na.rm = TRUE),
    flights = n()
  )
```

## 3.5.6 `.by`

-   `.by` allows you to group for just a single operation
    -   dont need to make a grouped dataframe
    -   dont need to ungroup a grouped dataframe when you're done
    -   dont need to surpress the multi-group warning message with `.group`

```{r}
# example with grouping by 1
flights |>
  summarize(
    delay = mean(dep_delay, na.rm = TRUE),
    n = n(),
    .by = month
  )

# example with grouping by multiple
flights |>
  summarize(
    delay = mean(dep_delay, na.rm = TRUE),
    n = n(),
    .by = c(origin,dest)
  )
```

## 3.5.7 Exercises

1.  Which carrier has the worst average delays? Challenge: can you disentangle the effects of bad airports vs. bad carriers? Why/why not? (Hint: think about `flights |> group_by(carrier, dest) |> summarize(n())`)

**Answer**: Without disentangling effects of bad airport and bad carrier (naive version), F9 appears to be the worst with an average delay of 21.92 min. For the challenge, if my weighted average provides a disentanglement then F9 still has the worst even after accounting for bad airports.

```{r}
# naive version
naive_df <-
  flights |> 
    group_by(carrier) |>
    summarize(avg_delay = mean(arr_delay, na.rm = TRUE)) |>
    arrange(desc(avg_delay)) # |>
    # filter(carrier == "YV")

avg_delay_YV_naive <- (naive_df |> filter(carrier == "YV"))$avg_delay

print(avg_delay_YV_naive)

# disentangle airport/flight version, v1 
# NOT sufficient since this is just getting the numerator from the average, so
# we are just comparing the sum of arr_delay for each carrier/dest. pair
# let's explore further below
  # flights |> 
  #   group_by(carrier, dest) |>
  #   summarize(
  #     avg_delay = mean(arr_delay, na.rm = TRUE),
  #     n = n(),
  #     num_flight_weighted_avg_delay = avg_delay*n,
  #     .groups = "keep"
  #     ) |>
  #   arrange(desc(num_flight_weighted_avg_delay))

# arrange by n 
flights |> 
  group_by(carrier, dest) |>
  summarize(
    n = n(),
    .groups = "keep"
    ) |>
  arrange(desc(n))

# calc avg_delay, then arrange by carrier 
flights |> 
  group_by(carrier, dest) |>
  summarize(
    avg_delay = mean(arr_delay, na.rm = TRUE),
    n = n(),
    .groups = "keep"
    ) |>
  arrange(desc(carrier))

# calc avg_delay, then arrange by dest 
flights |> 
  group_by(carrier, dest) |>
  summarize(
    avg_delay = mean(arr_delay, na.rm = TRUE),
    n = n(),
    .groups = "keep"
    ) |>
  arrange(desc(dest))

# let's try to give remove the effects of bad airports by doing a weighted average: sum_i avg_delay_i * n_i for every carrier where the size of i is the number of dest/carrier pairs for a given carrier
# arrange by carrier 
  # df_1 <-
  #   flights |> 
  #     # get the summands for numerator of weighted avg
  #     group_by(carrier, dest) |>
  #     summarize(
  #       avg_delay = mean(arr_delay, na.rm = TRUE),
  #       n = n(),
  #       .groups = "keep"
  #       ) |>
  #     arrange(desc(carrier)) |>
  #     mutate(summands = avg_delay*n) |>
  #   
  #     # ungroup and get the sums
  #     ungroup() |>
  #     group_by(carrier) |>
  #     summarize(
  #       numerator = 
  #     )
  # 
  # df_1 |> head()

df_1 <-
  flights |> 
    # get the summands for numerator of weighted avg
    group_by(carrier, dest) |>
    summarize(
      avg_delay = mean(arr_delay, na.rm = TRUE),
      n = n(),
      .groups = "keep"
      ) |>
  
    # ungroup and then group by carrier alone, so we can get a weighted
    # average wrt to carrier, weighting by counts of how many flights were to that dest for that carrier
    ungroup() |>
    group_by(carrier) |>
    summarize(
      weighted_avg_delay = weighted.mean(avg_delay, n, na.rm = TRUE),
      .groups = "keep"
    ) |>
    arrange(desc(weighted_avg_delay))

df_1 |> head()
filter(df_1,carrier=="YV")$weighted_avg_delay

df_1$weighted_avg_delay == naive_df$avg_delay # good, they are NOT equal! :)

df_1$weighted_avg_delay - naive_df$avg_delay # but they are pretty close :(

```

2.  Find the flights that are most delayed upon departure from each destination.

Answer: See below for top 5 most delayed upon departure flights FOR EACH destination.

```{r}
flights |>
  group_by(dest) |> 
  arrange(desc(dep_delay)) |>
  relocate(dest, dep_delay) |>
  slice_head(n=5) # NOT simply head(n=5), since we want most delayed for each destination.
```

3.  How do delays vary over the course of the day? Illustrate your answer with a plot.

Answer: See below. Originally, I thought delay seems to not have a strong correlation with time of day given the numerous vertical groups that exist for all the various x_time, y_delay combinations. These are the plots that have not been summarized and smoothed. The point of the chapter is that large datasets often need transformation to pull out the patterns. The transformed (summarized and smoothed) plot is inspired by resources 1 and 2.

```{r}
head(flights)
# TRANSFORMED DATA
temp <- 
  flights |>
    group_by(hour) |>
    summarize(avg_delay_by_hour = mean(dep_delay, na.rm = TRUE))

head(temp)
```

```{r}
ggplot(temp,aes(x = hour, y = avg_delay_by_hour))+
  geom_line(linetype = "dashed") +
  geom_point()

```

```{r}
# ALL UNTRANSFORMED DATA BELOW!
ggplot(flights,aes(x = dep_time, y = dep_delay, color = distance))+
  geom_point()
```

```{r}
# color by Posix time to see if time of year explains split along y=x
ggplot(flights,aes(x = dep_time, y = dep_delay, color = time_hour))+
  geom_point()
```

```{r}
# color by destination to see if pattern emerges to explain split along y=x
ggplot(flights,aes(x = dep_time, y = dep_delay, color = dest))+
  geom_point()
# THIS IS A TERRIBLE PLOT, TOO MANY DESINATIONS. and i guess doesnt make sense
# that the destination would affect the departure time. except maybe how the seasons
# vary more drastically the further you get from the equator??
```

```{r}
# color by origin to see if pattern emerges to explain split along y=x
ggplot(flights,aes(x = dep_time, y = dep_delay, color = origin))+
  geom_point()
```

```{r}
# color by origin to see if pattern emerges to explain split along y=x
ggplot(flights,aes(x = arr_time, y = arr_delay, color = origin))+
  geom_point()
```

```{r}
# color by origin to see if pattern emerges to explain split along y=x
ggplot(flights,aes(x = arr_time, y = dep_delay, color = origin))+
  geom_point()
```

```{r}
# color by origin to see if pattern emerges to explain split along y=x
ggplot(flights,aes(x = dep_time, y = arr_delay, color = origin))+
  geom_point()
```

4.  What happens if you supply a negative n to slice_min() and friends? Answer: `slice_min(group_by(temp,col_2),col_1,n=2)` – pipe equivalent `temp |> group_by(col_2) |> slice_min(col_1,n=2)` – means get first 2 rows whose value is minimum in col_1 for each group when grouping by col_2. Documentation from ?slice_min, explains `n < 0` will get \# of rows equal to num_rows minus n (as if n were positive) that are minimum in col_1 when grouping by col_2. See example below.

```{r}
temp <- tibble(col_1=1:10,col_2=c(rep("a",5),rep("b",5)))
temp

# slice_min(group_by(temp,col_2),col_1,1)
temp |> group_by(col_2) |> slice_min(col_1,n=2)

temp |> group_by(col_2) |> slice_min(col_1,n=-2)

```

5.  Explain what `count()` does in terms of the dplyr verbs you just learned. What does the sort argument to `count()` do? Answer: `count()`counts unique values when grouping by one or more variables. It's mathematically equivalent to `temp |> group_by(col_1,col_2) |> summarize(n=n())`. The sort argument sorts by the value of n

```{r}
temp <- tibble(col_1=1:10,
               col_2=c(rep("a",5),rep("b",5)),
               col_3=c(rep("male",3),rep("female",7)))
temp
count(temp,col_3,col_2,sort=TRUE)
temp |> group_by(col_3,col_2) |> summarize(n=n(),.groups="keep")
```

6.  Suppose we have the following tiny data frame:

```{r}
df <- tibble(
  x = 1:5,
  y = c("a", "b", "a", "a", "b"),
  z = c("K", "K", "L", "L", "K")
)
```

a.  Write down what you think the output will look like, then check if you were correct, and describe what `group_by()` does. Answer: I think `group_by()` will make two groups, one for rows where column y is "a" and one for rows where column y is "b". It will create a grouped dataframe that looks exactly like `df` except it now has the attribute \$groups, which contains the grouping y, as indicated by "Groups: y \[2\]" when you run the following.

```{r}
df |>
  group_by(y)
```

b.  Write down what you think the output will look like, then check if you were correct, and describe what `arrange()` does. Also, comment on how it’s different from the `group_by()` in part (a). Answer: I think `arrange()` will order the rows of `df` alphabetically by the column `y`. So rows 1,3,4 will be first followed by rows 2,5 when you run the following code.

```{r}
df |>
  arrange(y)
```

c.  Write down what you think the output will look like, then check if you were correct, and describe what the pipeline does.

*WRONG* Answer: The output will look like a dataframe with two rows and one column like the following: 2.66667 3.5

*CORRECT* Answer: The output will be a tibble dataframe with 2 rows and two columns. The first column will be the grouping variable (y), the second column will be the summary statistic calculated for the other input variable (x) after grouping on the grouping variable (y), which we dubbed mean_x. The dataframe will look like this when running the following (omitting the datatype of the columns): y mean_x 1 a 2.66667 2 b 3.5

8/3 = (1+3+4)/3, for group y=a (1+3+4)/3 =

```{r}
df |>
  group_by(y) |>
  summarize(mean_x = mean(x))
```

d.  Write down what you think the output will look like, then check if you were correct, and describe what the pipeline does. Then, comment on what the message says.

*WRONG* Answer: This will be the same as c, since the `.groups` argument was not specified so the 2nd grouping variable will be ignored.

*CORRECT* Answer: I misunderstood what the chapter means when it says "each summary peels off the last group". This just means that the groups attribute of the output will not have z anymore. Therefore, the dataframe will group by the combination y and z, creating 3 groups, then summarizing the mean of x for all 3 groups, looking like: a K 1 b K 3.5 \# 3.5 comes from (2+5)/2 a L 3.5 \# 3.5 comes from (3+4)/2

```{r}
df |>
  group_by(y, z) |>
  summarize(mean_x = mean(x))
```

e.  Write down what you think the output will look like, then check if you were correct, and describe what the pipeline does. How is the output different from the one in part (d)?

*WRONG* Answer: The same as part d, except now there is the multi group y,z instead of just a group y.

*CORRECT* Answer: I for some reason though .groups was set to "keep" and not "drop" my mistake. "drop" will mean there are no groups leftover, but the output dataframe will be the same as d in every other way.

```{r}
df |>
  group_by(y, z) |>
  summarize(mean_x = mean(x), .groups = "drop")

# EVEN IF THIS HAD BEEN IT, running groups(summarize(group_by)) shows two distinct groups rather than a single group y,z. Regardless of how R represents it, I do understand that there are 3 unique pairs of y,z; this is prob the most important thing.
# df |>
#   group_by(y, z) |>
#   summarize(mean_x = mean(x), .groups = "keep")
```

f.  Write down what you think the outputs will look like, then check if you were correct, and describe what each pipeline does. How are the outputs of the two pipelines different?

*HALF WRONG* Answer:

The first pipeline's 1st step creates a grouped dataframe on y and z. Then it summarizes the x value of the grouped dataframe's 3 groups. There will be 1 group left in the output dataframe because of summarizes() wonky group peeling.

The second pipeline 1st creates a grouped dataframe on y,z. Then it adds a new column called "mean(x)" to the grouped dataframe that is the mean of each row in the grouped dataframe. The mean of a single value will be that value, therefore it just adds a column called mean_x that has same value as x. There will be 2 groups left in the output dataframe, because mutate does not affect the groups of the input dataframe.

*CORRECT* Answer:

See above for first pipeline, this is correct.

As for the 2nd pipeline, verbs change their behavior to operate on groups if a grouped dataframe is input. The verb `mutate()` now computes the function `mean(x)` wrt to the rows of column x **of each group** then for every row in the original dataframe, it assigns the respective group mean for that row to the column mean_x (the number of rows won't be reduced as the first pipeline does)

```{r}
df |>
  group_by(y, z) |>
  summarize(mean_x = mean(x))

df |>
  group_by(y, z) |>
  mutate(mean_x = mean(x))
```

# 3.6 Don't use mere averages to measure performance

Using baseball batting dataset from Lahman, `Lahman::Batting` - H = num hits - AB = attempted bats (at bats) - we compute the hit percentage of each player

```{r}
batters <- Lahman::Batting |> 
  group_by(playerID) |> 
  summarize(
    performance = sum(H, na.rm = TRUE) / sum(AB, na.rm = TRUE),
    n = sum(AB, na.rm = TRUE)
  )
batters
```

Two key takeways, see plot below: 1. LAW OF LARGE NUMBERS: Variation in `performance` is larger among players with fewer AB. Plot is characteristic of a general truth: if you plot a summary statistics vs group size, variation decreases as sample size increases. 2. `performance` (skill) is positively correlated with opporunities to hit the ball, `n`, since teams want their best batters to have more chances to hit the ball

```{r}
batters |> 
  filter(n > 100) |> 
  ggplot(aes(x = n, y = performance)) +
  geom_point(alpha = 1 / 10) + 
  geom_smooth(se = FALSE)
```

Notice the idiom piping \|\> into ggplot, then switching to adding layers to plot with +

*Big takeway* ranking by a mere average doesn't necessarily result in getting the best players - sometimes those who attempted once and hit once, then "went out on top" will have a false "100% average AB". See resources below for solving this problem:

\- http://varianceexplained.org/r/empirical_bayes_baseball/\
- https://www.evanmiller.org/how-not-to-sort-by-average-rating.html.

# Resources

1.  https://mine-cetinkaya-rundel.github.io/r4ds-solutions/data-transform.html
2.  https://www.sthda.com/english/wiki/ggplot2-line-plot-quick-start-guide-r-software-and-data-visualization
